summarize(avg_season_HR=average(HR))%>%
filter(avg_season_HR > 600)%>%
arrange(desc(avg_season_HR))
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=avg(HR))%>%
filter(avg_season_HR > 600)%>%
arrange(desc(avg_season_HR))
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=mean(HR))%>%
filter(avg_season_HR > 600)%>%
arrange(desc(avg_season_HR))
bdat9d
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=mean(HR))%>%
arrange(desc(avg_season_HR))
bdat9d
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=mean(HR))%>%
arrange(desc(avg_season_HR))%>%
head(10)
bdat9d
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=mean(HR))%>%
arrange(desc(avg_season_HR))%>%
head(10)%>%
round(2)
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(round(avg_season_HR=mean(HR),)2)%>%
arrange(desc(avg_season_HR))%>%
head(10)%>%
)
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=mean(HR))%>%
arrange(desc(avg_season_HR))%>%
head(10)
bdat9d
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=round(mean(HR),2)%>%
arrange(desc(avg_season_HR))%>%
head(10)
)
bdat9d <- Batting %>%
group_by(playerID)%>%
summarize(avg_season_HR=round(mean(HR),2))%>%
arrange(desc(avg_season_HR))%>%
head(10)
bdat9d
bdat9d[dbl]
bdat9d[[dbl]
bdat10d <- Batting%>%
group_by(playerID)%>%
filter(HR>50 & yearID > 1950)
bdat10d
bdat10d <- Batting%>%
group_by(playerID)%>%
select(playerID,yearID,HR)%>%
filter(HR>50 & yearID > 1950)
bdat10d
bdat10d <- Batting%>%
group_by(playerID)%>%
select(playerID,yearID,HR)%>%
filter(HR>50 & yearID > 1950)%>%
arrange(desc(HR))
bdat10d
bdat10d[2]
bdat10d[3]
bdat10d[4,3]
bdat10d[HR]
bdat10d['HR']
bdat10d2 <- Batting%>%
group_by(playerID)%>%
summarize(maxHR=max(HR))%>%
filter(HR > 50 & yearID > 1950)%>%
arrange(desc(HR))
bdat10d2 <- Batting%>%
filter(HR > 50 & yearID > 1950)%>%
group_by(playerID)%>%
summarize(maxHR=max(HR))%>%
arrange(desc(HR))
bdat10d2 <- Batting%>%
filter(yearID > 1950)%>%
group_by(playerID)%>%
summarize(maxHR=max(HR))%>%
filter(HR > 50)%>%
arrange(desc(HR))
bdat10d2 <- Batting%>%
filter(yearID >= 1970)%>%
group_by(playerID)%>%
summarize(maxHR=max(HR))%>%
filter(maxHR > 50)%>%
arrange(desc(HR))
bdat10d2 <- Batting%>%
filter(yearID >= 1970)%>%
group_by(playerID)%>%
summarize(maxHR=max(HR))%>%
filter(maxHR > 50)%>%
arrange(desc(maxHR))
bdat10d2
Batting %>%
select(playerID,HR)%>
filter(playerID=='ruthba01')
bdat7d <- Batting %>%
filter(playerID=='ruthba01')%>%
group_by(playerID)%>%
summarize(career_HR=sum(HR))%>%
bdat7d <- Batting %>%
filter(playerID=='ruthba01')%>%
group_by(playerID)%>%
summarize(career_HR=sum(HR))%>%
bdat8d <- Batting %>%
group_by(playerID)%>%
summarize(career_HR=sum(HR))%>%
filter(career_HR > 600)%>%
arrange(desc(career_HR))
rbeta?
?rbeta
rbeta(100, 5, 2)
hist(rbeta(100, 5, 2))
hist(rbeta(100, 2, 5))
x1<-rbeta(100, 5, 2)
hist(x1)
x1<-rbeta(100, 2, 5)
hist(x1)
mean(x1)
22/x1
22/mean(x1)
x1 <- x1 * 74.8
hist(x1)
x1 <- x1 +10
hist(x1)
hist(x1, xlim = 0)
hist(x1, xlim = 80)
?rbeta
q1 = c(20, 22, 23, 30, 50)
rbeta(n = 100, q = q1)
rbeta(n = 100)
dbeta(n = 100, x = q1)
?rbinom
install.pckages("kernelKnn")
install.pckages("KernelKnn")
install.packages("KernelKnn")
library(KernelKnn)
12*13
11*11
15*15
pnorm(.25, 100, 15)
pnorm(x = .25, mean = 100, sd = 15)
pnorm(p = .25, mean = 100, sd = 15)
pnorm(q = .25, mean = 100, sd = 15)
rnorm(q = .25, mean = 100, sd = 15)
qnorm(q = .25, mean = 100, sd = 15)
qnorm(.25, 100, 15)
pnorm(89, 100, 15)
pnorm(115, 100, 15)
pnorm(115, 100, 15)
pnorm(115, 100, 15)
pnorm(105, 100, 15)
pnorm(120, 100, 15)
pnorm(125, 100, 15)
qnorm(.75, 100, 15)
qnorm(3, 100, 15)
qnorm(1, 100, 15)
qnorm(.99, 100, 15)
qnorm(.01, 100, 15)
qnorm(.73, 100, 15)
library(readxl)
SAHD <- read_excel("C:/Users/hydro/Desktop/Machine Learning II/SAHD.xls",
col_types = c("numeric", "numeric", "numeric",
"numeric", "numeric", "text", "numeric",
"numeric", "numeric", "numeric",
"numeric"))
View(SAHD)
SAHD$famhist <- factor()
View(SAHD)
SAHD$famhist <- factor(SAHD$famhist, levels = c("Present", "Absent"),labels = c("Present", "Absent"))
str
str(SAHD)
SAHD$chd <- factor(SAHD$chd, levels = c("1", "0"),labels = c("1", "0"))
str(SAHD)
summary(SAHD)
chart.Correlation(SAHD)
library(PerformanceAnalytics)
chart.Correlation(SAHD)
chart.Correlation("SAHD")
str(SAHD)
str(SAHD[c(1:5, 7:10)])
chart.Correlation(SAHD[c(1:5, 7:10)])
chart.Correlation(SAHD[c(1:5, 7:10)], pch=20)
SAHD2 <- read_excel("C:/Users/hydro/Desktop/Machine Learning II/SAHD.xls",
)
SAHD2 <- read_excel("C:/Users/hydro/Desktop/Machine Learning II/SAHD.xls")
chart.Correlation(SAHD2)
str(SAHD2)
str(SAHD2[c(1:5,7:11])
str(SAHD2[c(1:5,7:11)])
chart.Correlation(SAHD2)
chart.Correlation(SAHD2[c(1:5,7:11)])
chart.Correlation(SAHD2[c(1:5,7:11)], pch=19)
library(readr)
Asian_Fusion_Data <- read_csv("C:/Users/hydro/Desktop/Machine Learning II/Asian_Fusion_Data.csv")
View(Asian_Fusion_Data)
View(SAHD)
plot(sbp ~ chd, data=SAHD)
plot(tobacco ~ chd, data=SAHD)
plot(ldl ~ chd, data=SAHD)
plot(adiposity ~ chd, data=SAHD)
plot(famhist ~ chd, data=SAHD)
plot(typea ~ chd, data=SAHD)
plot(obesity ~ chd, data=SAHD)
plot(alcohol ~ chd, data=SAHD)
plot(age ~ chd, data=SAHD)
plot(chd ~ chd, data=SAHD)
chart.Correlation(SAHD2[c(1:5,7:11)], pch=19)
sahhd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
View(sahdd)
sahhd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv');
sahhd
dim(sahhd)
dim(SAHD)
table(SAHD)
head(tobacco)
attach(SAHD)
head(tobacco)
head(SAHD$tobacco)
table(chd)
summary(glm(SAHD))
?apply
?apply
?lapply
table(chd)
summary(SAHD)
normalize(c(1,2,3,4,5))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),c("ID", "Sex", "Pop", "PopSex","GOL","NOL","BNL","BBH","XCB")];
head(HBNMF)
head(Howells)
dim(Howells)
dim(HBNMF)
library(MASS);
HBNMF.loo <- lda(PopSex ~ GOL+NOL+BNL+BBH+XCB, data = HBNMF, prior = c(0.25,0.25,0.25,0.25), CV = TRUE)
confusionMatrix(HBNMF$PopSex, HBNMF.loo$class)
library(caret)
library(MASS);
confusionMatrix(HBNMF$PopSex, HBNMF.loo$class)
plot(menarche)
plot(menarche$Age ~ menarche$Total)
?seq
holdout <- seq(1,nrow(HBNMF), 2)
holdout
HBNMF.loo <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior = c(0.25,0.25,0.25,0.25), CV = TRUE)
HBNMF.t <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior = c(0.25,0.25,0.25,0.25), subset = holdout, CV = T)
confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.t$class)
train <- seq(1,nrow(HBNMF), 4)
HBNMF.2 <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior =c(0.25,0.25,0.25,0.25), subset = -train, CV = T)
confusionMatrix(HBNMF[-train,"PopSex"], HBNMF.2$class)
data()
dim(Titanic)
View(Titanic)
str(Titanic)
?dim
dim(Titanic)
dim(diamonds)
dim(data)
dim(economics)
names(economics)
?economics
pnorm(.5, 100, 15)
qnorm(.5, 100, 15)
qnorm(.99, 30000, 10000)
pnorm(100000, 30000, 10000)
5*6
7*8
123*256
# what proportion to holdout?
sprop = 0.3
holdout <- sample(nrow(HBNMF), round(sprop*nrow(HBNMF)))
# CV needed to produce ANY CV output
HBNMF.r <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior =
c(0.25,0.25,0.25,0.25), subset = holdout, CV = T)
confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.r$class)
confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.r$class)
confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.r$class)
sprop = 0.3
holdout <- sample(nrow(HBNMF), round(sprop*nrow(HBNMF)))
HBNMF.r <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior =
c(0.25,0.25,0.25,0.25), subset = holdout, CV = T)
confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.r$class)
for (i in seq(500)) # will make 500 or... 1000!
{
holdout <- sample(nrow(HBNMF), round(sprop*nrow(HBNMF)))
HBNMF.t <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior = c(0.25,0.25,0.25,0.25), subset =
holdout, CV = T)
Accuracies[i] <- confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.t$class)$overall["Accuracy"]
}
Accuracies
for (i in seq(500)) # will make 500 or... 1000!
{
holdout <- sample(nrow(HBNMF), round(sprop*nrow(HBNMF)))
HBNMF.t <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior = c(0.25,0.25,0.25,0.25), subset =
holdout, CV = T)
Accuracies[i] <- confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.t$class)$overall["Accuracy"]
}
Accuracies <- c(0.00)
for (i in seq(500)) # will make 500 or... 1000!
{
holdout <- sample(nrow(HBNMF), round(sprop*nrow(HBNMF)))
HBNMF.t <- lda(HBNMF[5:9],HBNMF$PopSex, data = HBNMF, prior = c(0.25,0.25,0.25,0.25), subset =
holdout, CV = T)
Accuracies[i] <- confusionMatrix(HBNMF[holdout,"PopSex"], HBNMF.t$class)$overall["Accuracy"]
}
Accuracies
mean(Accuracies)
plot(density(Accuracies))
plot(density(Accuracies), col.fill="steelblue")
plot(density(Accuracies), fill.col="steelblue")
density(Accuracies)
library(sqldf)
??sqldf
`sqldf-package`
knitr::opts_chunk$set(echo = TRUE)
install.packages("mvoutlier")
install.packages("mvoutliers")
library(readr)
Asian_Fusion_Data <- read_csv("C:/Users/hydro/Desktop/Asian_Fusion_Data.csv")
View(Asian_Fusion_Data)
library(readr)
Asian_Fusion_Data <- read_csv("C:/Users/hydro/Desktop/Asian_Fusion_Data.csv")
View(Asian_Fusion_Data)
library(caret)
library(MASS)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
H4A.all <- lda(H4A[2:72],H4A$PopSex, data = H4a, prior = c(0.25,0.25,0.25,0.25), CV = T)
confusionMatrix(H4A$PopSex, H4A.all$class)
for (i in seq(1000))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
Accuracies <- c(0.00)
for (i in seq(1000))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
for (i in seq(1000))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
}
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
H4A.R <- lda(H4A[inTrain,c(2:72)], H4A[inTrain,"PopSex"], data = HA4, prior =
c(0.25,0.25,0.25,0.25), subset = -inTrain, CV = T)
Accuracies[i] <- confusionMatrix(H4A[as.numeric(rownames(H4A.R$posterior)),"PopSex"],
H4A.R$class)$overall["Accuracy"]
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(1000))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
H4A.R <- lda(H4A[inTrain,c(2:72)], H4A[inTrain,"PopSex"], data = HA4, prior =
c(0.25,0.25,0.25,0.25), subset = -inTrain, CV = T)
Accuracies[i] <- confusionMatrix(H4A[as.numeric(rownames(H4A.R$posterior)),"PopSex"],
H4A.R$class)$overall["Accuracy"]
}
summary(Accuracies)
boxplot(Accuracies)
boxplot(Accuracies, col="blue")
plot(density(Accuracies))
library(klaR)
install.packages("klaR")
library(klaR)
H4A_swf
H4A_swf <- stepclass(H4A[2:72], H4A$PopSex, "lda", improvement = 0.005, direction =
"forward", fold = 10)
plot(H4A_swf)
plot(H4A_swf, pch=19)
H4A_swf$model
for (i in seq(1000))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
H4A.RB <- lda(PopSex ~ GOL + XCB + NLH + JUB + XML + FRS + FOL + BAA, data = H4A, prior =
c(0.25,0.25,0.25,0.25), subset = -inTrain, CV = T)
Accuracies[i] <- confusionMatrix(H4A[as.numeric(rownames(H4A.RB$posterior)),"PopSex"],
H4A.RB$class)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
H4A_swfq <- stepclass(H4A[2:72], H4A$PopSex, "qda", improvement = 0.005,, fold = 5, maxvars = 15)
confusionMatrix(m4A$PopSex,H4A.q$class)
for (i in seq(1000))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
# testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
H4A.RB <- qda(PopSex ~ GOL + XCB + OBH + XML + FOL + VRR, data = H4A, prior =
c(0.25,0.25,0.25,0.25), subset = -inTrain, CV = T)
Accuracies[i] <- confusionMatrix(H4A[as.numeric(rownames(H4A.RB$posterior)),"PopSex"],
H4A.RB$class)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv")) update(knn4, list(.k = 3))
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
knn4
update(knn4, list(.k = 3))
knn4
knn4$modelType
names(knn4)
knn4$xlevels
knn4$xlevels[1]
knn4$finalModel
knn4$finalModel[1,4]
knn4$perfNames
knn4$perfNames[2]
knn4$maximize[2]
knn4$maximize
knn4$times
confusionMatrix(knn4)
knn4_pred <- predict(knn4,newdata = testing)
knn4_pred
confusionMatrix(knn4_pred,testing$PopSex)
for (i in seq(20)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
# testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
plot(density(Accuracies))
summary(Accuracies)
View(Accuracies)
Accuracies
mean(Accuracies)
summary(Accuracies)
ci.median(Accuracies, conf = 0.95)
quantile(Accuracies, c(.025, 0.975))
iris %>%
ggvis(x = ~Sepal.Width,
y = ~Sepal.Length,
fill = ~Species,
size = ~Petal.Length
) %>%
layer_points()
library(ggvis)
iris %>%
ggvis(x = ~Sepal.Width,
y = ~Sepal.Length,
fill = ~Species,
size = ~Petal.Length
) %>%
layer_points()
faithful %>% ggvis(x = ~waiting, y = ~eruptions, size = ~eruptions, opacity := 0.5, fill := "blue", stroke := "black") %>% layer_points()
library(devtools)
library(blogdown)
new_site(theme="budparr/gohugo-theme-ananke")
setwd("C:/Users/hydro/Desktop/DSCC/blog0")
new_site(theme="budparr/gohugo-theme-ananke")
build_site()
serve_site()
